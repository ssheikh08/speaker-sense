# SpeakerSense - Frontend

SpeakerSense is a web application that allows users to upload video files, extract audio from the videos, and generate transcripts using Azure Cognitive Services' Speech to Text API. This README focuses on the frontend implementation of the application.

For a demo of the application please checkout out our [hosted application](https://speaker-sense.vercel.app/video-upload)

## Table of Contents

- [Project Overview](#project-overview)
- [Development Setup](#development-setup)
- [Running the Development Server](#running-the-development-server)
- [Building the Project](#building-the-project)
- [Running Unit Tests](#running-unit-tests)
- [Running End-to-End Tests](#running-end-to-end-tests)
- [Further Help](#further-help)

## Project Overview

The frontend of the application is built using Angular CLI version 16.1.8. It provides a user-friendly interface for uploading video files, displaying video content, and presenting generated transcripts.

The core functionalities of the frontend include:
- Accepting user uploads of video files.(mp4)
- Displaying uploaded videos.
- Showing the transcript generated by the backend.

## Development Setup

1. Make sure you have [Node.js](https://nodejs.org/) installed on your machine.

2. Navigate to the project directory:
    `cd speaker-sense-frontend`

3. Install dependencies:
    `npm install`

4. If using your own lambda, update apiUrl on line 9 in file `speaker-sense-app/speaker-sense-frontend/src/app/upload.service.ts`

## Build the project

1. Run TypeScript compiler:
    `npm tsc`

2. To build the application run:
    `npm run build` 

Application will run on `http://localhost:4200/`

## Contact

For any questions or support, please contact [Shoaib Sheikh] at [sheiksho28@gmail.com] or [https://github.com/ssheikh08].

